\documentclass[11pt]{ctexart}  
\usepackage{ctex}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
% \usepackage[hidelinks]{hyperref} 去除超链接的红色框
\usepackage{setspace}
\usepackage{titlesec}
\usepackage{float} % 调用该包能够使用[H]

\pagestyle{plain} % 去除页眉，但是保留页脚编号，都去掉plain换empty
\begin{document}
\tableofcontents % 目录，注意要运行两下或者vscode保存两下才能显示
% \singlespacing
\clearpage
\section{DQN算法}
\begin{algorithm}[H] % [H]固定位置
    \floatname{algorithm}{{DQN算法}}  
    \renewcommand{\thealgorithm}{} % 去掉算法标号
	\caption{} 
    \renewcommand{\algorithmicrequire}{\textbf{输入:}}  
    \renewcommand{\algorithmicensure}{\textbf{输出:}} 
	\begin{algorithmic}
		% \REQUIRE $n \geq 0 \vee x \neq 0$ % 输入
		% \ENSURE $y = x^n$ % 输出
		\STATE 初始化策略网络参数$\theta$ % 初始化
		\STATE 复制参数到目标网络$\hat{Q} \leftarrow Q$
		\STATE 初始化经验回放$D$
		\FOR {回合数 = $1,M$}
			\STATE 重置环境，获得初始状态$s_t$
			\FOR {时步 = $1,t$}
				\STATE 根据$\varepsilon-greedy$策略采样动作$a_t$
				\STATE 环境根据$a_t$反馈奖励$s_t$和下一个状态$s_{t+1}$
				\STATE 存储transition即$(s_t,a_t,r_t,s_{t+1})$到经验回放$D$中
				\STATE 更新环境状态$s_{t+1} \leftarrow s_t$
				\STATE {\bfseries 更新策略：}
				\STATE 从$D$中采样一个batch的transition
				\STATE 计算实际的$Q$值，即$y_{j}= \begin{cases}r_{j} & \text {对于终止状态} s_{j+1} \\ r_{j}+\gamma \max _{a^{\prime}} Q\left(s_{j+1}, a^{\prime} ; \theta\right) & \text {对于非终止状态} s_{j+1}\end{cases}$
				\STATE 对损失 $\left(y_{j}-Q\left(s_{j}, a_{j} ; \theta\right)\right)^{2}$关于参数$\theta$做随机梯度下降
			\ENDFOR
			\STATE 每$C$个回合复制参数$\hat{Q}\leftarrow Q$(此处也可像原论文中放到小循环中改成每$C$步，但没有每$C$个回合稳定)
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

\clearpage

\section{SoftQ算法}
\begin{algorithm}[H]
    \floatname{algorithm}{{SoftQ算法}}  
    \renewcommand{\thealgorithm}{} % 去掉算法标号
	\caption{}  
	\begin{algorithmic}
		\STATE 初始化参数$\theta$和$\phi$% 初始化
		\STATE 复制参数$\bar{\theta} \leftarrow \theta, \bar{\phi} \leftarrow \phi$
		\STATE 初始化经验回放$D$
		\FOR {回合数 = $1,M$}
			\FOR {时步 = $1,t$}
				\STATE 根据$\mathbf{a}_{t} \leftarrow f^{\phi}\left(\xi ; \mathbf{s}_{t}\right)$采样动作，其中$\xi \sim \mathcal{N}(\mathbf{0}, \boldsymbol{I})$
				\STATE 环境根据$a_t$反馈奖励$s_t$和下一个状态$s_{t+1}$
				\STATE 存储transition即$(s_t,a_t,r_t,s_{t+1})$到经验回放$D$中
				\STATE 更新环境状态$s_{t+1} \leftarrow s_t$
				\STATE {\bfseries 更新soft Q函数参数：}
				\STATE 对于每个$s^{(i)}_{t+1}$采样$\left\{\mathbf{a}^{(i, j)}\right\}_{j=0}^{M} \sim q_{\mathbf{a}^{\prime}}$
				\STATE 计算empirical soft values $V_{\mathrm{soft}}^{\theta}\left(\mathbf{s}_{t}\right)=\alpha \log \mathbb{E}_{q_{\mathbf{a}^{\prime}}}\left[\frac{\exp \left(\frac{1}{\alpha} Q_{\mathrm{soft}}^{\theta}\left(\mathbf{s}_{t}, \mathbf{a}^{\prime}\right)\right)}{q_{\mathbf{a}^{\prime}}\left(\mathbf{a}^{\prime}\right)}\right]$
				\STATE 计算empirical gradient $J_{Q}(\theta)=\mathbb{E}_{\mathbf{s}_{t} \sim q_{\mathbf{s}_{t}}, \mathbf{a}_{t} \sim q_{\mathbf{a}_{t}}}\left[\frac{1}{2}\left(\hat{Q}_{\mathrm{soft}}^{\bar{\theta}}\left(\mathbf{s}_{t}, \mathbf{a}_{t}\right)-Q_{\mathrm{soft}}^{\theta}\left(\mathbf{s}_{t}, \mathbf{a}_{t}\right)\right)^{2}\right]$
				\STATE 根据$J_{Q}(\theta)$使用ADAM更新参数$\theta$
				\STATE {\bfseries 更新策略：}
				\STATE  对于每个$s^{(i)}_{t}$采样$\left\{\xi^{(i, j)}\right\}_{j=0}^{M} \sim \mathcal{N}(\mathbf{0}, \boldsymbol{I})$
				\STATE 计算$\mathbf{a}_{t}^{(i, j)}=f^{\phi}\left(\xi^{(i, j)}, \mathbf{s}_{t}^{(i)}\right)$
				\STATE 使用经验估计计算$\begin{aligned} \Delta f^{\phi}\left(\cdot ; \mathbf{s}_{t}\right)=& \mathbb{E}_{\mathbf{a}_{t} \sim \pi^{\phi}}\left[\left.\kappa\left(\mathbf{a}_{t}, f^{\phi}\left(\cdot ; \mathbf{s}_{t}\right)\right) \nabla_{\mathbf{a}^{\prime}} Q_{\mathrm{soft}}^{\theta}\left(\mathbf{s}_{t}, \mathbf{a}^{\prime}\right)\right|_{\mathbf{a}^{\prime}=\mathbf{a}_{t}}\right.\\ &\left.+\left.\alpha \nabla_{\mathbf{a}^{\prime}} \kappa\left(\mathbf{a}^{\prime}, f^{\phi}\left(\cdot ; \mathbf{s}_{t}\right)\right)\right|_{\mathbf{a}^{\prime}=\mathbf{a}_{t}}\right] \end{aligned}$
				\STATE 计算经验估计$\frac{\partial J_{\pi}\left(\phi ; \mathbf{s}_{t}\right)}{\partial \phi} \propto \mathbb{E}_{\xi}\left[\Delta f^{\phi}\left(\xi ; \mathbf{s}_{t}\right) \frac{\partial f^{\phi}\left(\xi ; \mathbf{s}_{t}\right)}{\partial \phi}\right]$，即$\hat{\nabla}_{\phi} J_{\pi}$
				\STATE 根据$\hat{\nabla}_{\phi} J_{\pi}$使用ADAM更新参数$\phi$
				\STATE 
			\ENDFOR
			\STATE 每$C$个回合复制参数$\bar{\theta} \leftarrow \theta, \bar{\phi} \leftarrow \phi$
		\ENDFOR	
	\end{algorithmic}
\end{algorithm}

\end{document}